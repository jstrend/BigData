{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNprqtOtvgWozQ0v1YcL8U1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jstrend/BigData2023/blob/main/00_Getting%20Started%20with%20Anaconda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KE0pCExrLi2"
      },
      "outputs": [],
      "source": [
        "# Get data from internet\n",
        "import requests\n",
        "\n",
        "# Read HTML\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Database connection\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "# Visualization\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect directly to Wikipedia and read the HTML source into memory\n",
        "response = requests.get('https://en.wikipedia.org/w/index.php',\n",
        "                        params={'title': 'List_of_countries_by_literacy_rate',\n",
        "                                'oldid': 809221941})\n",
        "html = response.content\n",
        "\n",
        "# Parse the soup of HTML tags\n",
        "soup = BeautifulSoup(html, 'lxml')\n",
        "rows = soup.find('table', attrs={'class':'sortable wikitable'}).find_all('tr')\n",
        "\n",
        "# Read the table row-by-row\n",
        "# The first three rows are ignored\n",
        "literacy = []\n",
        "for row in rows[3:]:\n",
        "    columns = row.find_all('td')\n",
        "\n",
        "    name = columns[0].text.strip()\n",
        "    try:\n",
        "        overall = float(columns[1].text[:-1])\n",
        "        male = float(columns[2].text[:-1])\n",
        "        female = float(columns[3].text[:-1])\n",
        "    except:\n",
        "        overall = male = female = None\n",
        "\n",
        "    literacy.append({'Country':name, 'overall literacy':overall,\n",
        "                     'male literacy':male, 'female literacy':female})\n",
        "\n",
        "## Pandas DataFrame\n",
        "literacy = pd.DataFrame.from_dict(literacy)\n",
        "literacy.head()"
      ],
      "metadata": {
        "id": "cK-h4uEgrNXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5U3Ue76OrQRj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}